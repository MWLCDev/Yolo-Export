# Got error "TensorRT model exported with a different version than 8.2.0.6" wo I will try to export the model from the same docker image
# it doesn't have cuda enabled in it
FROM mwlvdev/jetson-nano-ubuntu:bionic-torch1.11-cp38-cuda10.2

# Set noninteractive mode for apt-get
ENV DEBIAN_FRONTEND noninteractive

# Setup environment variables for CUDA
ENV PATH="/usr/local/cuda/bin:${PATH}"
ENV LD_LIBRARY_PATH="/usr/local/cuda/lib64:/usr/local/cuda/targets/aarch64-linux/lib:/usr/lib/aarch64-linux-gnu:/usr/lib/aarch64-linux-gnu/tegra:/usr/local/cuda/extras/CUPTI/lib64"
# Set environment variable
ENV LD_LIBRARY_PATH=/usr/lib/aarch64-linux-gnu/tegra:${LD_LIBRARY_PATH}

ENV PATH="/usr/local/cuda/bin:${PATH}"
# Update and install dependencies
RUN apt-get update && apt-get install -y --no-install-recommends \
    cuda-toolkit-10-2 \
    libcudnn8 \
    wget \
    python3.8 \
    python3.8-venv \
    python3.8-dev \
    python3-venv \
    python3.8-distutils \
    python3-pip \
    gcc git \
    apt-transport-https \
    ca-certificates \
    curl

# Ensure that pip is up-to-date
RUN wget https://bootstrap.pypa.io/get-pip.py -O get-pip.py && \
    python3.8 get-pip.py

# Create and activate virtual environment, then install the package
RUN python3.8 -m venv /venv && \
    /bin/bash -c "source /venv/bin/activate && pip install --upgrade pip"

# Add NVIDIA repository for TensorRT
RUN curl -s -L https://repo.download.nvidia.com/jetson/jetson-ota-public.asc | apt-key add - && \
    echo "deb https://repo.download.nvidia.com/jetson/common r32.7 main" > /etc/apt/sources.list.d/nvidia-l4t-apt-source.list && \
    echo "deb https://repo.download.nvidia.com/jetson/t194 r32.7 main" >> /etc/apt/sources.list.d/nvidia-l4t-apt-source.list && \
    apt-get update

# Install TensorRT and other libraries
RUN apt-get install -y --no-install-recommends \
    libnvinfer-dev=8.2.1-1+cuda10.2 \
    libnvinfer-plugin-dev=8.2.1-1+cuda10.2 \
    python3-libnvinfer=8.2.1-1+cuda10.2 \
    libnvinfer8\
    libnvinfer-plugin8\
    libopencv-python && \
    apt-get clean && \
    rm -rf /var/lib/apt/lists/*

# Install runtime libraries matching the development versions
RUN apt-get update && \
    apt-get install -y libnvinfer8 libnvinfer-plugin8

# Download the correct TensorRT wheel file for aarch64 (this step is important)
RUN wget -O /tmp/tensorrt-8.2.0.6-cp38-none-linux_aarch64.whl https://forums.developer.nvidia.com/uploads/short-url/hASzFOm9YsJx6VVFrDW1g44CMmv.whl && \
    /bin/bash -c "source /venv/bin/activate && pip install /tmp/tensorrt-8.2.0.6-cp38-none-linux_aarch64.whl"


# Downloads to user config dir
RUN mkdir -p /root/.config/Ultralytics && \
    wget https://github.com/ultralytics/assets/releases/download/v0.0.0/Arial.ttf -O /root/.config/Ultralytics/Arial.ttf && \
    wget https://github.com/ultralytics/assets/releases/download/v0.0.0/Arial.Unicode.ttf -O /root/.config/Ultralytics/Arial.Unicode.ttf

# Clone the YOLOv8 repository and install it in the virtual environment
RUN git clone https://github.com/ultralytics/ultralytics.git /usr/src/ultralytics && \
    /bin/bash -c "source /venv/bin/activate && pip install /usr/src/ultralytics"

# Copy application code to the working directory
COPY /export_following/ /app/

# Set the working directory to /app
WORKDIR /app/

# Ensure the script has executable permissions
RUN chmod +x ./app.py

# Command that runs when the container starts
CMD ["python3 app.py"]

# For testing to keep the container running indefinitely
# ENTRYPOINT ["tail", "-f", "/dev/null"]
